# PDF Chatbot with Gemini Flash 1.5

A Streamlit application that allows users to upload PDF documents and chat with them using Google's Gemini Flash 1.5 model.

## Features

- ðŸ“„ PDF upload and text extraction
- ðŸ” Semantic search using FAISS vector database
- ðŸ’¬ Conversational AI with chat history
- ðŸ“‘ Source citations with page numbers

## Setup


ðŸ“‚ Project Structure
pdf-chatbot/
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ modules/               # Core modules (embedding, retrieval, etc.)
â”œâ”€â”€ utils/                 # Utility functions
â”œâ”€â”€ storage/               # Local storage for processed data
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ .env                   # Environment variables (not committed)

âš™ï¸ Installation & Setup
1. Clone the repository
git clone https://github.com/Abhiaero/PDF_Chatbot.git
cd PDF_Chatbot

2. Create and activate a virtual environment

Windows (PowerShell):

python -m venv venv
venv\Scripts\activate


Linux/Mac (bash):

python3 -m venv venv
source venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

4. Configure environment variables

Create a .env file in the root folder and add your API keys.
For example, if youâ€™re using OpenAI:

OPENAI_API_KEY=your_api_key_here


âš ï¸ .env is ignored by Git â€” each user must create their own.

â–¶ï¸ Running the App

Run with Streamlit:

streamlit run app.py


Open your browser at:
ðŸ‘‰ http://localhost:8501

ðŸ› ï¸ Requirements

Python 3.11+

Streamlit

OpenAI API key (or other LLM provider depending on your setup)

ðŸ“Œ Notes

If you want to reset the chatbotâ€™s knowledge, clear the storage/ folder.

Large binary files should be handled with Git LFS.

Contributions are welcome! Fork the repo and submit a PR.



# How is the conversation history maintained?
Conversation History: Maintained in Streamlit's session state as a list of message dictionaries with role, content, timestamp, and sources. Last 6 messages are used as context for follow-up questions to maintain conversation flow.
Implementation: st.session_state.messages stores entire chat history, and the RAG prompt includes recent conversation context for coherent multi-turn dialogues.

# Limitations:
Current Limitations: Handles only text-based PDFs (not scanned/image PDFs), and may struggle with complex layouts or tables that span multiple pages due to chunking constraints.
Technical Constraints: Limited by Gemini API rate limits and cannot process very large PDFs (>100 pages) efficiently due to local FAISS index size limitations.